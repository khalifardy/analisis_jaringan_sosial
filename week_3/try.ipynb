{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 's2QFOvxH7qmmB35TGmu583Ca3'\n",
    "CONSUMER_KEY_SECRET ='0tM0suzpqSs96f0MQucens837yM1KVMFDwT5nUoaBT2XgQcOht'\n",
    "BEARER = 'AAAAAAAAAAAAAAAAAAAAAAXSwAEAAAAAAy1vX36lEBtmOJ7HzyNXU9wJcY8%3DMZ5qe8DH8xWua8WIy2oHSjrXUpeDsMaRVkfetiHOIQvn5m7M0X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_KEY_SECRET)\n",
    "api = tweepy.API(login)\n",
    "client = tweepy.Client(bearer_token=BEARER)\n",
    "query = '#naturalisasi -is:retweet'\n",
    "tweets = client.search_recent_tweets(query=query, max_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('tweets.csv', 'w',encoding='utf-8')\n",
    "csvwriter = csv.writer(csvfile)\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q='#Python -filter:retweets', tweet_mode='extended',lang=\"id\", since='2024-10-1', until='2024-10-2').items(10):\n",
    "    text = tweet.full_text\n",
    "    user = tweet.user.name\n",
    "    created = tweet.created_at\n",
    "    csvwriter.writerow([created, text.encode('utf-8'), user])\n",
    "csvWriter = csv.writer(csvFile)\n",
    "csvfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.search_tweets( tweet_mode='extended',lang=\"id\", since='2022-01-01', until='2021-01-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawl Data\n",
    "\n",
    "filename = 'naturalisasi.csv'\n",
    "search_keyword = 'naturalisasi since:2024-10-03 until:2024-10-04 lang:id'\n",
    "limit = 10\n",
    "\n",
    "!npx -y tweet-harvest@2.6.1 -o \"{filename}\" -s \"{search_keyword}\" --tab \"LATEST\" -l {limit} --token {'787fc6049a3a3cc6f09100a76e484f471fb59e7e'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_oauthlib import OAuth1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.x.com/2/users/by/username/\"\n",
    "\n",
    "# Parameter pencarian\n",
    "params = {\n",
    "    \"q\": \"nasa\",\n",
    "    \"result_type\": \"popular\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = '1547056734669193216-YMyZWqDHb1pkJA7fCpLSoU33zPRlr7'\n",
    "ACCESS_TOKEN_SECRET = 'YYmHuCGAS0eKihgOTHK66xDmug2TpSmMgd4V8ptS8QwQm'\n",
    "username = 'BagusSanto50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuth1(CONSUMER_KEY, CONSUMER_KEY_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# Melakukan permintaan GET ke API\n",
    "response = requests.get(url+username, auth=auth)\n",
    "\n",
    "# Memeriksa apakah respons berhasil\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Mengambil data dalam format JSON\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://twitter.com/BagusSanto50: SSLError(MaxRetryError(\"HTTPSConnectionPool(host='twitter.com', port=443): Max retries exceeded with url: /BagusSanto50 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)')))\"))\n",
      "4 requests to https://twitter.com/BagusSanto50 failed, giving up.\n",
      "Errors: SSLError(MaxRetryError(\"HTTPSConnectionPool(host='twitter.com', port=443): Max retries exceeded with url: /BagusSanto50 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)')))\")), SSLError(MaxRetryError(\"HTTPSConnectionPool(host='twitter.com', port=443): Max retries exceeded with url: /BagusSanto50 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)')))\")), SSLError(MaxRetryError(\"HTTPSConnectionPool(host='twitter.com', port=443): Max retries exceeded with url: /BagusSanto50 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)')))\")), SSLError(MaxRetryError(\"HTTPSConnectionPool(host='twitter.com', port=443): Max retries exceeded with url: /BagusSanto50 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)')))\"))\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://twitter.com/BagusSanto50 failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m username \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBagusSanto50\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musername\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Searching for tweets mentioning the user\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43msntwitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTwitterUserScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/functools.py:1001\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    999\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m-> 1001\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1003\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/.env_3.7/lib/python3.11/site-packages/snscrape/base.py:207\u001b[0m, in \u001b[0;36mScraper.entity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentity\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 207\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_entity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/.env_3.7/lib/python3.11/site-packages/snscrape/modules/twitter.py:1792\u001b[0m, in \u001b[0;36mTwitterUserScraper._get_entity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_entity\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1792\u001b[0m \t\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_guest_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_isUserId:\n\u001b[1;32m   1794\u001b[0m \t\tfieldName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_name\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/.env_3.7/lib/python3.11/site-packages/snscrape/modules/twitter.py:825\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._ensure_guest_token\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_guestTokenManager\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieving guest token\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 825\u001b[0m \tr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_baseUrl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponseOkCallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_guest_token_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m (match \u001b[38;5;241m:=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.cookie = decodeURIComponent\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt=(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+); Max-Age=10800; Domain=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.twitter\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.com; Path=/; Secure\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m);\u001b[39m\u001b[38;5;124m'\u001b[39m, r\u001b[38;5;241m.\u001b[39mtext)):\n\u001b[1;32m    827\u001b[0m \t\t_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound guest token in HTML\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/.env_3.7/lib/python3.11/site-packages/snscrape/base.py:275\u001b[0m, in \u001b[0;36mScraper._get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 275\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/.env_3.7/lib/python3.11/site-packages/snscrape/base.py:271\u001b[0m, in \u001b[0;36mScraper._request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[1;32m    269\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39mfatal(msg)\n\u001b[1;32m    270\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39mfatal(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mErrors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m ScraperException(msg)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReached unreachable code\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mScraperException\u001b[0m: 4 requests to https://twitter.com/BagusSanto50 failed, giving up."
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "username = 'BagusSanto50'\n",
    "query = f'to:{username}'  # Searching for tweets mentioning the user\n",
    "\n",
    "\n",
    "sntwitter.TwitterUserScraper(username).entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:25<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "scrapper = Nitter(log_level=1,skip_instance_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper.get_tweets('KMiqdarsah',mode='user',number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-Oct-24 13:51:28 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "06-Oct-24 13:51:31 - Empty page on https://nitter.privacydev.net\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hasil \u001b[38;5;241m=\u001b[39m \u001b[43mscrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_profile_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBentVuijk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdetail\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/.env_3.7/lib/python3.11/site-packages/ntscraper/nitter.py:1163\u001b[0m, in \u001b[0;36mNitter.get_profile_info\u001b[0;34m(self, username, max_retries, instance, mode)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(username, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1162\u001b[0m     username \u001b[38;5;241m=\u001b[39m username\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m-> 1163\u001b[0m     profile_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_profile_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m profile_info \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1165\u001b[0m         profile_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing_list\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_follow_list(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musername\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/following\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/.env_3.7/lib/python3.11/site-packages/ntscraper/nitter.py:1009\u001b[0m, in \u001b[0;36mNitter._profile_info\u001b[0;34m(self, username, max_retries, instance)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m soup \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m is_encrypted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_instance_encrypted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# Extract id if the banner exists, no matter if the instance uses base64 or not\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile-banner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_encrypted:\n",
      "File \u001b[0;32m~/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/.env_3.7/lib/python3.11/site-packages/ntscraper/nitter.py:116\u001b[0m, in \u001b[0;36mNitter._is_instance_encrypted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/x\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m soup \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid instance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    119\u001b[0m     soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile-card-avatar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/enc/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile-card-avatar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    122\u001b[0m ):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid instance"
     ]
    }
   ],
   "source": [
    "hasil = scrapper.get_profile_info(username='BentVuijk',mode='detail',max_retries=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'public_metrics': {'followers_count': 212, 'following_count': 702, 'tweet_count': 10295, 'listed_count': 1, 'like_count': 1213}, 'protected': False, 'description': 'Holla Holla Bola ‚öΩüèÉ', 'username': 'BentVuijk', 'location': 'Indonesia', 'verified': False, 'id': '264927696', 'created_at': '2011-03-12T17:59:00.000Z', 'name': 'Bent_Vuijk', 'profile_image_url': 'https://pbs.twimg.com/profile_images/783501597003309056/jcH5jSI1_normal.jpg'}}\n"
     ]
    }
   ],
   "source": [
    "url = 'https://api.x.com/2/users/by/username/'\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAAXSwAEAAAAAAy1vX36lEBtmOJ7HzyNXU9wJcY8%3DMZ5qe8DH8xWua8WIy2oHSjrXUpeDsMaRVkfetiHOIQvn5m7M0X\"\n",
    "\n",
    "path_params = 'BentVuijk'\n",
    "params = {\n",
    "    'user.fields': 'created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld'\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "}\n",
    "\n",
    "response = requests.get(url+path_params, headers=headers, params=params)\n",
    "\n",
    "# Memeriksa apakah respons berhasil\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Mengambil data dalam format JSON\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'public_metrics': {'followers_count': 212,\n",
       "   'following_count': 702,\n",
       "   'tweet_count': 10295,\n",
       "   'listed_count': 1,\n",
       "   'like_count': 1213},\n",
       "  'protected': False,\n",
       "  'description': 'Holla Holla Bola ‚öΩüèÉ',\n",
       "  'username': 'BentVuijk',\n",
       "  'location': 'Indonesia',\n",
       "  'verified': False,\n",
       "  'id': '264927696',\n",
       "  'created_at': '2011-03-12T17:59:00.000Z',\n",
       "  'name': 'Bent_Vuijk',\n",
       "  'profile_image_url': 'https://pbs.twimg.com/profile_images/783501597003309056/jcH5jSI1_normal.jpg'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mTweet Harvest [v2.6.1]\u001b[39m\u001b[22m\n",
      "\u001b[1m\u001b[32m\u001b[39m\u001b[22m\n",
      "\u001b[34mResearch by \u001b[39m\u001b[1m\u001b[34mHelmi Satria\u001b[39m\u001b[22m\u001b[34m\u001b[39m\n",
      "\u001b[34mUse it for Educational Purposes only!\u001b[39m\n",
      "\u001b[34m\u001b[39m\n",
      "\u001b[33mThis script uses Chromium Browser to crawl data from Twitter with \u001b[1myour Twitter auth token\u001b[22m.\u001b[39m\n",
      "\u001b[33mPlease enter your Twitter auth token when prompted.\u001b[39m\n",
      "\u001b[33m\u001b[39m\n",
      "\u001b[31m\u001b[1mNote:\u001b[22m\u001b[39m Keep your access token secret! Don't share it with anyone else.\n",
      "\u001b[31m\u001b[1mNote:\u001b[22m\u001b[39m This script only runs on your local device.\n",
      "\n",
      "\u001b[34m\u001b[39m\n",
      "\u001b[34mOpening twitter search page...\u001b[39m\n",
      "\u001b[34m\u001b[39m\n",
      "\u001b[90m\u001b[39m\n",
      "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[33m\u001b[39m\n",
      "\u001b[33mFilling in keywords: naturalisasi near:Jakarta,\u001b[39m\n",
      "\u001b[33m\u001b[39m\n",
      "\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[34m\u001b[39m\n",
      "\u001b[34m\u001b[39m\n",
      "\u001b[34mYour tweets saved to: /home/khalifardy/Dokumen/ruang_kerja/code/kuliah/ANALISIS_JARINGAN_SOSIAL/analisis_jaringan_sosial/week_3/tweets-data/naturalisasi_geolocation.csv\u001b[39m\n",
      "\u001b[33mTotal tweets saved: 19\u001b[39m\n",
      "Got 19 tweets, done scrolling...\n"
     ]
    }
   ],
   "source": [
    "filename = 'naturalisasi_geolocation.csv'\n",
    "search_keyword = 'naturalisasi near:\"Jakarta, Indonesia\" within:50km since:2024-10-03 until:2024-10-04 lang:id'\n",
    "limit = 10\n",
    "\n",
    "!npx -y tweet-harvest@2.6.1 -o \"{filename}\" -s \"{search_keyword}\" --tab \"LATEST\" -l {limit} --token {'787fc6049a3a3cc6f09100a76e484f471fb59e7e'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
